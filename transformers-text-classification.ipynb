{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-17T05:28:50.668851Z","iopub.execute_input":"2021-06-17T05:28:50.669455Z","iopub.status.idle":"2021-06-17T05:28:50.687106Z","shell.execute_reply.started":"2021-06-17T05:28:50.669359Z","shell.execute_reply":"2021-06-17T05:28:50.686009Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/news-extracted-dataset/News_category_extract_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:29:06.522097Z","iopub.execute_input":"2021-06-17T05:29:06.522507Z","iopub.status.idle":"2021-06-17T05:29:12.273052Z","shell.execute_reply.started":"2021-06-17T05:29:06.522473Z","shell.execute_reply":"2021-06-17T05:29:12.272044Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom keras.utils import to_categorical\nfrom sklearn import preprocessing","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:40:37.801235Z","iopub.execute_input":"2021-06-17T05:40:37.801590Z","iopub.status.idle":"2021-06-17T05:40:38.493368Z","shell.execute_reply.started":"2021-06-17T05:40:37.801560Z","shell.execute_reply":"2021-06-17T05:40:38.492220Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n        super(TransformerBlock, self).__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = keras.Sequential(\n            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:31:24.471423Z","iopub.execute_input":"2021-06-17T05:31:24.471812Z","iopub.status.idle":"2021-06-17T05:31:24.479743Z","shell.execute_reply.started":"2021-06-17T05:31:24.471777Z","shell.execute_reply":"2021-06-17T05:31:24.479005Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class TokenAndPositionEmbedding(layers.Layer):\n    def __init__(self, maxlen, vocab_size, embed_dim):\n        super(TokenAndPositionEmbedding, self).__init__()\n        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-1]\n        positions = tf.range(start=0, limit=maxlen, delta=1)\n        positions = self.pos_emb(positions)\n        x = self.token_emb(x)\n        return x + positions","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:31:29.168222Z","iopub.execute_input":"2021-06-17T05:31:29.168700Z","iopub.status.idle":"2021-06-17T05:31:29.174893Z","shell.execute_reply.started":"2021-06-17T05:31:29.168669Z","shell.execute_reply":"2021-06-17T05:31:29.173803Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/news-extracted-dataset/News_category_extract_dataset.csv')\ndata.drop(columns=['Unnamed: 0'],inplace=True)\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:38:18.236627Z","iopub.execute_input":"2021-06-17T05:38:18.236996Z","iopub.status.idle":"2021-06-17T05:38:19.421639Z","shell.execute_reply.started":"2021-06-17T05:38:18.236966Z","shell.execute_reply":"2021-06-17T05:38:19.420495Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(70257, 4)"},"metadata":{}}]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n# The maximum number of words to be used. (most frequent)\nMAX_NB_WORDS = 50000\n# Max number of words in each complaint.\nMAX_SEQUENCE_LENGTH = 200\n# This is fixed.\nEMBEDDING_DIM = 100\n\ntokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\ntokenizer.fit_on_texts(data['clean_text'].values)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:38:23.972572Z","iopub.execute_input":"2021-06-17T05:38:23.972968Z","iopub.status.idle":"2021-06-17T05:38:25.897868Z","shell.execute_reply.started":"2021-06-17T05:38:23.972933Z","shell.execute_reply":"2021-06-17T05:38:25.896797Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 43059 unique tokens.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nX = tokenizer.texts_to_sequences(data['clean_text'].values)\nX = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', X.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:39:24.466590Z","iopub.execute_input":"2021-06-17T05:39:24.466952Z","iopub.status.idle":"2021-06-17T05:39:26.643848Z","shell.execute_reply.started":"2021-06-17T05:39:24.466923Z","shell.execute_reply":"2021-06-17T05:39:26.642571Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Shape of data tensor: (70257, 200)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nlabels=data['category'].values\nlabels_clf=le.fit_transform(labels)\nclasses=le.classes_","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:39:58.004497Z","iopub.execute_input":"2021-06-17T05:39:58.004876Z","iopub.status.idle":"2021-06-17T05:39:58.715227Z","shell.execute_reply.started":"2021-06-17T05:39:58.004844Z","shell.execute_reply":"2021-06-17T05:39:58.714133Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"cat_labels=labels_clf\ncat_labels = to_categorical(cat_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:40:43.073178Z","iopub.execute_input":"2021-06-17T05:40:43.073570Z","iopub.status.idle":"2021-06-17T05:40:43.084962Z","shell.execute_reply.started":"2021-06-17T05:40:43.073535Z","shell.execute_reply":"2021-06-17T05:40:43.084180Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nY=cat_labels\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.30, random_state = 42)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)\nprint(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:41:02.612959Z","iopub.execute_input":"2021-06-17T05:41:02.613348Z","iopub.status.idle":"2021-06-17T05:41:02.659620Z","shell.execute_reply.started":"2021-06-17T05:41:02.613313Z","shell.execute_reply":"2021-06-17T05:41:02.658627Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(49179, 200) (49179, 4)\n(21078, 200) (21078, 4)\n[[   0    0    0 ...   94  727  232]\n [   0    0    0 ...  174   18  212]\n [   0    0    0 ...  402  505 1275]\n ...\n [   0    0    0 ... 5098  121 7858]\n [   0    0    0 ... 4497 1108 1736]\n [   0    0    0 ...  130 6186  209]]\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab_size = 50000\n# Max number of words in each complaint.\nmaxlen = 200\n# This is fixed.\n\nprint(len(X_train), \"Training sequences\")\nprint(len(X_test), \"Validation sequences\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T05:42:49.677988Z","iopub.execute_input":"2021-06-17T05:42:49.678544Z","iopub.status.idle":"2021-06-17T05:42:49.685287Z","shell.execute_reply.started":"2021-06-17T05:42:49.678512Z","shell.execute_reply":"2021-06-17T05:42:49.684111Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"49179 Training sequences\n21078 Validation sequences\n","output_type":"stream"}]},{"cell_type":"code","source":"embed_dim = 100  # Embedding size for each token\nnum_heads = 2  # Number of attention heads\nff_dim = 32  # Hidden layer size in feed forward network inside transformer\n\ninputs = layers.Input(shape=(maxlen,))\nembedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\nx = embedding_layer(inputs)\ntransformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\nx = transformer_block(x)\nx = layers.GlobalAveragePooling1D()(x)\nx = layers.Dropout(0.1)(x)\nx = layers.Dense(20, activation=\"relu\")(x)\nx = layers.Dropout(0.1)(x)\noutputs = layers.Dense(4, activation=\"softmax\")(x)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:17:56.850872Z","iopub.execute_input":"2021-06-17T06:17:56.851251Z","iopub.status.idle":"2021-06-17T06:17:57.055773Z","shell.execute_reply.started":"2021-06-17T06:17:56.851219Z","shell.execute_reply":"2021-06-17T06:17:57.054749Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:17:58.966766Z","iopub.execute_input":"2021-06-17T06:17:58.967357Z","iopub.status.idle":"2021-06-17T06:17:58.977524Z","shell.execute_reply.started":"2021-06-17T06:17:58.967311Z","shell.execute_reply":"2021-06-17T06:17:58.976318Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 200)]             0         \n_________________________________________________________________\ntoken_and_position_embedding (None, 200, 100)          5020000   \n_________________________________________________________________\ntransformer_block_2 (Transfo (None, 200, 100)          87632     \n_________________________________________________________________\nglobal_average_pooling1d_2 ( (None, 100)               0         \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 100)               0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 20)                2020      \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 20)                0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 4)                 84        \n=================================================================\nTotal params: 5,109,736\nTrainable params: 5,109,736\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nepochs = 2\nbatch_size = 64\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:18:03.025663Z","iopub.execute_input":"2021-06-17T06:18:03.026424Z","iopub.status.idle":"2021-06-17T06:25:52.925415Z","shell.execute_reply.started":"2021-06-17T06:18:03.026369Z","shell.execute_reply":"2021-06-17T06:25:52.924387Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/2\n615/615 [==============================] - 233s 377ms/step - loss: 1.0529 - accuracy: 0.5334 - val_loss: 0.3484 - val_accuracy: 0.8863\nEpoch 2/2\n615/615 [==============================] - 237s 385ms/step - loss: 0.2517 - accuracy: 0.9217 - val_loss: 0.3038 - val_accuracy: 0.8996\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}